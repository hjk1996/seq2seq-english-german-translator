{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq eng to german.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjDlPnNLufoW"
      },
      "source": [
        "라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9yYx-GSuhvb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33asSmB4ukkK"
      },
      "source": [
        "텍스트 데이터 전처리에 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pi4HwTjumt2"
      },
      "source": [
        "#유니코드 문자를 아스키로 변경함\n",
        "\n",
        "#독일어에 사용되는 알파벳 세트를 영어에 사용되는 알파벳 세트와 일치시키기 위한 작업임\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "    #문장을 소문자로 변경시키고 아스키 문자로 변경함.\n",
        "    sent = unicode_to_ascii(sent.lower())\n",
        "\n",
        "    # 단어와 구두점 사이에 공백을 만듬.\n",
        "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외하고는 전부 공백으로 변환.\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "    # 한 칸을 넘는 공백은 제거\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent\n",
        "\n",
        "def load_preprocessed_data(num_samples):\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"deu.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "\n",
        "      # src 데이터와 tar 데이터 분리\n",
        "      src_line, tar_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      # src 데이터 전처리\n",
        "      src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # tar 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      # 디코더의 입력값으로 들어갈 데이터에는 <sos> 태그를 붙여주고,\n",
        "      tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      # 디코더의 출력값과 비교될 타겟 데이터에는 <eos> 태그를 붙여줌.\n",
        "      tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line_input)\n",
        "      decoder_input.append(tar_line_input)\n",
        "      decoder_target.append(tar_line_target)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "  \n",
        "  return encoder_input, decoder_input, decoder_target\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrIG-f8yvb7K"
      },
      "source": [
        "텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAqtdyr0vdJi",
        "outputId": "c5af7291-3173-4aa1-f1e8-ccf689feee7e"
      },
      "source": [
        "# 30,000개의 텍스트 데이터를 전처리해서 사용함\n",
        "# teacher forcing을 위해 decoder에 들어갈 input이 필요함.\n",
        "sents_en_in, sents_deu_in, sents_deu_out = load_preprocessed_data(30000)\n",
        "\n",
        "print(len(sents_en_in))\n",
        "print(len(sents_deu_in))\n",
        "print(len(sents_deu_out))\n",
        "\n",
        "print(sents_en_in[0])\n",
        "print(sents_deu_in[0])\n",
        "print(sents_deu_out[0])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000\n",
            "30000\n",
            "30000\n",
            "['go', '.']\n",
            "['<sos>', 'geh', '.']\n",
            "['geh', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIiXzwasxuqx"
      },
      "source": [
        "단어 토큰화 시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWcJvZUkxybZ",
        "outputId": "78eff307-15bb-4ad7-f6c1-360ce68533e6"
      },
      "source": [
        "# 텍스트 데이터 전처리 과정에서 이미 한 번 필터시켰기 때문에 따로 필터를 거치고 소문자 변환 작업을 할 필요가 없음.\n",
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_deu = Tokenizer(filters=\"\", lower=False)\n",
        "\n",
        "# 각 토크나이저 학습\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "tokenizer_deu.fit_on_texts(sents_deu_in + [\"<eos>\"])\n",
        "\n",
        "\n",
        "print(tokenizer_deu.word_index[\"<sos>\"])\n",
        "print(tokenizer_deu.word_index[\"<eos>\"])\n",
        "\n",
        "# Keras 공식 문서에 의하면 Embedding 레이어에 들어가기 위해서 1을 더해줘야함.\n",
        "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "deu_vocab_size = len(tokenizer_deu.word_index) + 1\n",
        "\n",
        "print(f\"the size of the english vocabulary is {en_vocab_size}\")\n",
        "print(f\"the size of the english vocabulary is {deu_vocab_size}\")\n",
        "\n",
        "tokenized_en_in = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "tokenized_deu_in = tokenizer_deu.texts_to_sequences(sents_deu_in)\n",
        "tokenized_deu_out = tokenizer_deu.texts_to_sequences(sents_deu_out)\n",
        "\n",
        "\n",
        "print(tokenized_en_in[5482])\n",
        "print(tokenized_deu_in[5482])\n",
        "print(tokenized_deu_out[5482])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "7058\n",
            "the size of the english vocabulary is 4460\n",
            "the size of the english vocabulary is 7059\n",
            "[20, 5, 19, 7, 4]\n",
            "[1, 94, 12, 10, 83, 6]\n",
            "[94, 12, 10, 83, 6, 7058]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egBqqiCyVNJ1"
      },
      "source": [
        "인덱스-단어 사전, 단어-인덱스 사전 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gak-ZHjP5c8"
      },
      "source": [
        "en_to_index = tokenizer_en.word_index\n",
        "index_to_en = tokenizer_en.index_word\n",
        "\n",
        "deu_to_index = tokenizer_deu.word_index\n",
        "index_to_deu = tokenizer_deu.index_word"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LN1D-VW3wYQ"
      },
      "source": [
        "시퀸스 데이터에 패딩 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvcWDq0F3vBq",
        "outputId": "64809c44-bdab-40e6-9eaf-2b68fbd5aedf"
      },
      "source": [
        "padded_en_in = pad_sequences(tokenized_en_in, padding='post')\n",
        "padded_deu_in = pad_sequences(tokenized_deu_in, padding='post')\n",
        "padded_deu_out = pad_sequences(tokenized_deu_out, padding='post')\n",
        "\n",
        "# 각 입력값의 패딩 길이 확인.\n",
        "print(len(padded_en_in[0]))\n",
        "print(len(padded_deu_in[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxeaf8RUw-vZ"
      },
      "source": [
        "훈련, 검증 데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQQRrMZvxAse",
        "outputId": "efac3695-5ef4-4fb4-d34d-f7d273717d00"
      },
      "source": [
        "# shuffle\n",
        "indices = np.arange(padded_en_in.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)\n",
        "\n",
        "encoder_input = padded_en_in[indices]\n",
        "decoder_input = padded_deu_in[indices]\n",
        "decoder_output = padded_deu_out[indices]\n",
        "\n",
        "# 분할\n",
        "n_train = int(encoder_input.shape[0]*0.9)\n",
        "\n",
        "train_encoder_input = encoder_input[:n_train, :]\n",
        "train_decoder_input = decoder_input[:n_train, :]\n",
        "train_decoder_output = decoder_output[:n_train, :]\n",
        "\n",
        "val_encoder_input = encoder_input[n_train:, :]\n",
        "val_decoder_input = decoder_input[n_train:, :]\n",
        "val_decoder_output = decoder_output[n_train:, :]\n",
        "\n",
        "print(train_encoder_input.shape)\n",
        "print(val_encoder_input.shape)\n",
        "\n",
        "print(train_decoder_input.shape)\n",
        "print(val_decoder_input.shape)\n",
        "\n",
        "print(train_decoder_output.shape)\n",
        "print(val_decoder_output.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26430 11794  3989 ... 22805 12049  2228]\n",
            "(27000, 7)\n",
            "(3000, 7)\n",
            "(27000, 12)\n",
            "(3000, 12)\n",
            "(27000, 12)\n",
            "(3000, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2RrYuPK6CcZ"
      },
      "source": [
        "모델 만들기 위해 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhcyZojl6F7g"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Masking, LSTM, Input\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flaCFTgF6TWY"
      },
      "source": [
        "seq2seq 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5JIqT216UqM",
        "outputId": "e2b778fa-8f34-40ae-bf73-6caacc5f7145"
      },
      "source": [
        "# 임베딩 크기\n",
        "embedding_size = 100\n",
        "# LSTM 레이어의 셀 개수\n",
        "latent_size = 50\n",
        "\n",
        "encoder_input = Input(shape=(None, ))\n",
        "encoder_embedding_layer = Embedding(input_dim=en_vocab_size, output_dim=embedding_size)\n",
        "encoder_embedding_output = encoder_embedding_layer(encoder_input)\n",
        "# 0으로 패딩된 시퀸스는 건너뛰도록 마스킹 레이어를 추가해줌.\n",
        "encoder_masking_output = Masking(mask_value=0.0)(encoder_embedding_output)\n",
        "encoder_lstm_layer = LSTM(units=latent_size, return_state=True)\n",
        "encoder_lstm_output, encoder_state_h, encoder_state_c = encoder_lstm_layer(encoder_masking_output)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = Input(shape=(None, ))\n",
        "decoder_embedding_layer = Embedding(input_dim=deu_vocab_size, output_dim=embedding_size)\n",
        "decoder_embedding_output = decoder_embedding_layer(decoder_input)\n",
        "# 0으로 패딩된 시퀸스는 건너뛰도록 마스킹 레이어를 추가해줌.\n",
        "decoder_masking_output = Masking(mask_value=0.0)(decoder_embedding_output)\n",
        "# many to many이므로 return_sequences를 True로 설정해줌.\n",
        "decoder_lstm_layer = LSTM(units=latent_size, return_state=True, return_sequences=True)\n",
        "decoder_lstm_output, _, _ = decoder_lstm_layer(decoder_masking_output, initial_state=encoder_states)\n",
        "# 독일어 어휘의 개수만큼 Dense 레이어의 유닛을 설정해줌.\n",
        "decoder_dense_layer = Dense(units=deu_vocab_size, activation=\"softmax\")\n",
        "decoder_dense_output = decoder_dense_layer(decoder_lstm_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_dense_output])\n",
        "model.compile(optimizer='rmsprop', metrics=['acc'], loss=\"sparse_categorical_crossentropy\")\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 100)    446000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    705900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 100)    0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 100)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50), (None,  30200       masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 30200       masking_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 7059)   360009      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,572,309\n",
            "Trainable params: 1,572,309\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcmvt1TA_7GM"
      },
      "source": [
        "seq2seq 모델 훈련시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGJzN-53_8Ni",
        "outputId": "f02bfd9c-29d5-4b16-e488-f11caf3ed9c6"
      },
      "source": [
        "model.fit(x=[train_encoder_input, train_decoder_input], \n",
        "          y=train_decoder_output, \n",
        "          validation_data=([val_encoder_input, val_decoder_input], val_decoder_output),\n",
        "          batch_size=128,\n",
        "          epochs=50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "211/211 [==============================] - 20s 49ms/step - loss: 3.5292 - acc: 0.5251 - val_loss: 2.2625 - val_acc: 0.5990\n",
            "Epoch 2/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 2.0028 - acc: 0.6942 - val_loss: 1.8597 - val_acc: 0.7171\n",
            "Epoch 3/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.7459 - acc: 0.7273 - val_loss: 1.7103 - val_acc: 0.7412\n",
            "Epoch 4/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.6085 - acc: 0.7507 - val_loss: 1.5981 - val_acc: 0.7586\n",
            "Epoch 5/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.5070 - acc: 0.7657 - val_loss: 1.5278 - val_acc: 0.7682\n",
            "Epoch 6/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.4346 - acc: 0.7758 - val_loss: 1.4677 - val_acc: 0.7773\n",
            "Epoch 7/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 1.3767 - acc: 0.7833 - val_loss: 1.4194 - val_acc: 0.7836\n",
            "Epoch 8/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 1.3259 - acc: 0.7898 - val_loss: 1.3788 - val_acc: 0.7892\n",
            "Epoch 9/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 1.2802 - acc: 0.7961 - val_loss: 1.3448 - val_acc: 0.7945\n",
            "Epoch 10/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.2384 - acc: 0.8016 - val_loss: 1.3083 - val_acc: 0.7995\n",
            "Epoch 11/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.2001 - acc: 0.8062 - val_loss: 1.2818 - val_acc: 0.8029\n",
            "Epoch 12/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.1655 - acc: 0.8108 - val_loss: 1.2568 - val_acc: 0.8061\n",
            "Epoch 13/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.1333 - acc: 0.8147 - val_loss: 1.2329 - val_acc: 0.8099\n",
            "Epoch 14/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 1.1042 - acc: 0.8187 - val_loss: 1.2138 - val_acc: 0.8120\n",
            "Epoch 15/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.0768 - acc: 0.8222 - val_loss: 1.1988 - val_acc: 0.8143\n",
            "Epoch 16/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.0501 - acc: 0.8260 - val_loss: 1.1783 - val_acc: 0.8168\n",
            "Epoch 17/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.0251 - acc: 0.8295 - val_loss: 1.1582 - val_acc: 0.8197\n",
            "Epoch 18/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 1.0026 - acc: 0.8327 - val_loss: 1.1455 - val_acc: 0.8211\n",
            "Epoch 19/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.9816 - acc: 0.8359 - val_loss: 1.1340 - val_acc: 0.8230\n",
            "Epoch 20/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.9620 - acc: 0.8389 - val_loss: 1.1235 - val_acc: 0.8244\n",
            "Epoch 21/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.9434 - acc: 0.8424 - val_loss: 1.1110 - val_acc: 0.8270\n",
            "Epoch 22/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.9256 - acc: 0.8453 - val_loss: 1.1017 - val_acc: 0.8291\n",
            "Epoch 23/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.9083 - acc: 0.8480 - val_loss: 1.0903 - val_acc: 0.8301\n",
            "Epoch 24/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.8890 - acc: 0.8508 - val_loss: 1.0773 - val_acc: 0.8310\n",
            "Epoch 25/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.8694 - acc: 0.8538 - val_loss: 1.0669 - val_acc: 0.8344\n",
            "Epoch 26/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.8520 - acc: 0.8567 - val_loss: 1.0539 - val_acc: 0.8355\n",
            "Epoch 27/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.8363 - acc: 0.8593 - val_loss: 1.0458 - val_acc: 0.8372\n",
            "Epoch 28/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.8215 - acc: 0.8619 - val_loss: 1.0401 - val_acc: 0.8389\n",
            "Epoch 29/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.8079 - acc: 0.8647 - val_loss: 1.0305 - val_acc: 0.8407\n",
            "Epoch 30/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7952 - acc: 0.8671 - val_loss: 1.0271 - val_acc: 0.8408\n",
            "Epoch 31/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7837 - acc: 0.8691 - val_loss: 1.0221 - val_acc: 0.8413\n",
            "Epoch 32/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7724 - acc: 0.8715 - val_loss: 1.0170 - val_acc: 0.8437\n",
            "Epoch 33/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7622 - acc: 0.8738 - val_loss: 1.0147 - val_acc: 0.8445\n",
            "Epoch 34/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.7525 - acc: 0.8758 - val_loss: 1.0102 - val_acc: 0.8456\n",
            "Epoch 35/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.7430 - acc: 0.8778 - val_loss: 1.0059 - val_acc: 0.8457\n",
            "Epoch 36/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.7342 - acc: 0.8798 - val_loss: 1.0051 - val_acc: 0.8459\n",
            "Epoch 37/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7255 - acc: 0.8816 - val_loss: 1.0045 - val_acc: 0.8455\n",
            "Epoch 38/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.7174 - acc: 0.8833 - val_loss: 0.9979 - val_acc: 0.8479\n",
            "Epoch 39/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7095 - acc: 0.8849 - val_loss: 0.9962 - val_acc: 0.8484\n",
            "Epoch 40/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.7017 - acc: 0.8865 - val_loss: 0.9950 - val_acc: 0.8487\n",
            "Epoch 41/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.6943 - acc: 0.8877 - val_loss: 0.9923 - val_acc: 0.8486\n",
            "Epoch 42/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6874 - acc: 0.8891 - val_loss: 0.9888 - val_acc: 0.8488\n",
            "Epoch 43/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6809 - acc: 0.8905 - val_loss: 0.9868 - val_acc: 0.8503\n",
            "Epoch 44/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6745 - acc: 0.8916 - val_loss: 0.9859 - val_acc: 0.8504\n",
            "Epoch 45/50\n",
            "211/211 [==============================] - 7s 34ms/step - loss: 0.6682 - acc: 0.8929 - val_loss: 0.9842 - val_acc: 0.8502\n",
            "Epoch 46/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6619 - acc: 0.8939 - val_loss: 0.9829 - val_acc: 0.8509\n",
            "Epoch 47/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6560 - acc: 0.8952 - val_loss: 0.9804 - val_acc: 0.8520\n",
            "Epoch 48/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6503 - acc: 0.8963 - val_loss: 0.9778 - val_acc: 0.8514\n",
            "Epoch 49/50\n",
            "211/211 [==============================] - 7s 35ms/step - loss: 0.6448 - acc: 0.8973 - val_loss: 0.9785 - val_acc: 0.8519\n",
            "Epoch 50/50\n",
            "211/211 [==============================] - 7s 33ms/step - loss: 0.6397 - acc: 0.8984 - val_loss: 0.9774 - val_acc: 0.8519\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8386831450>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA7kiakUKue1"
      },
      "source": [
        "인코더 모델 빌드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8wQViV5K01Z",
        "outputId": "abd77bbf-4492-4daf-923c-be9882d49339"
      },
      "source": [
        "encoder_model = Model(encoder_input, encoder_states)\n",
        "\n",
        "encoder_model.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 100)         446000    \n",
            "_________________________________________________________________\n",
            "masking (Masking)            (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 50), (None, 50),  30200     \n",
            "=================================================================\n",
            "Total params: 476,200\n",
            "Trainable params: 476,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SIyifXSM7GY"
      },
      "source": [
        "디코더 모델 빌드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkOCiWdXNJPQ",
        "outputId": "f8a52f70-38ac-4a55-920b-5a46e21e0248"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(latent_size,))\n",
        "decoder_state_input_c = Input(shape=(latent_size,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_embedding_output2 = decoder_embedding_layer(decoder_input)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm_layer(decoder_embedding_output2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "decoder_outputs2 = decoder_dense_layer(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_input] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2\n",
        ")\n",
        "\n",
        "decoder_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    705900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 30200       embedding_1[1][0]                \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 7059)   360009      lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,096,109\n",
            "Trainable params: 1,096,109\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKEoS8SnPY9E"
      },
      "source": [
        "eng to deu 번역 함수 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-6UeG_4Pb8r"
      },
      "source": [
        "def decode_sentences(sentences):\n",
        "    \n",
        "    \n",
        "    results = []\n",
        "    sequenced_sentences = tokenizer_en.texts_to_sequences(sentences)\n",
        "    padded_sequences = pad_sequences(sequenced_sentences, maxlen=7, padding=\"post\")\n",
        "\n",
        "    for i in range(padded_sequences.shape[0]):\n",
        "      padded_sequence = padded_sequences[i, :].reshape(1, -1)\n",
        "      \n",
        "      # 입력으로부터 인코더의 상태를 얻음\n",
        "      states_value = encoder_model.predict(padded_sequence)\n",
        "\n",
        "\n",
        "      target_seq = np.zeros((1, 1))\n",
        "      target_seq[0, 0] = deu_to_index['<sos>']\n",
        "\n",
        "      sentence = \"\"\n",
        "\n",
        "\n",
        "      while True:\n",
        "        output, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        output_word_index = np.argmax(np.squeeze(output))\n",
        "        output_word = index_to_deu[output_word_index]\n",
        "\n",
        "        if output_word == \"<eos>\" or len(sentence) > 50:\n",
        "          break\n",
        "        \n",
        "\n",
        "        sentence = sentence + \" \" + output_word\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = output_word_index\n",
        "      \n",
        "      results.append(sentence)\n",
        "\n",
        "    return results"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sZrPCe1XG3e"
      },
      "source": [
        "단어 번역 실험하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilqc3_2OXFeY",
        "outputId": "e93d39ea-87b0-4aa6-b743-341a96934015"
      },
      "source": [
        "input_sentences = [\"hello\", \"how are you\", \"nice to meet you\", \"where is your mother?\"]\n",
        "results = decode_sentences(input_sentences)\n",
        "print(results)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ?', ' wie sind sie ?', ' beschaftigt sie ?', ' wo ist deine .']\n"
          ]
        }
      ]
    }
  ]
}